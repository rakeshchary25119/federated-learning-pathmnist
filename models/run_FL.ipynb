{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkiVYC2aMHu8",
    "outputId": "2e6afc0a-b042-4f73-cf8e-6c9ea1e3cc59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
      "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.2)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.24.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.6)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.7.0)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (42.0.8)\n",
      "Requirement already satisfied: grpcio!=1.64.2,!=1.65.1,!=1.65.2,!=1.65.4,!=1.65.5,!=1.66.0,!=1.66.1,<2.0.0,>=1.60.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.67.1)\n",
      "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (0.0.2)\n",
      "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (0.12.1)\n",
      "Requirement already satisfied: protobuf<5.0.0,>=4.25.2 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (4.25.5)\n",
      "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (3.21.0)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (2.1.0)\n",
      "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (1.1.0)\n",
      "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (0.12.5)\n",
      "Requirement already satisfied: ray==2.10.0 in /usr/local/lib/python3.10/dist-packages (from flwr[simulation]) (2.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (24.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (1.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0->flwr[simulation]) (2.32.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43.0.0,>=42.0.4->flwr[simulation]) (1.17.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (13.9.4)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr[simulation]) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<0.13.0,>=0.12.5->flwr[simulation]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<0.13.0,>=0.12.5->flwr[simulation]) (2.18.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0->flwr[simulation]) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0->flwr[simulation]) (2024.8.30)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.13.0,>=0.12.5->flwr[simulation]) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision medmnist flwr[simulation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3i9zgjITMVVJ"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg, FedAdagrad\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
    "\n",
    "\n",
    "from medmnist import INFO, Evaluator\n",
    "import medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0y_P4AMW6kt",
    "outputId": "5869fbe0-02fd-45d2-dbe3-2d093b803d24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n"
     ]
    }
   ],
   "source": [
    "# Global Variables for Datasets\n",
    "dataset_info = INFO['pathmnist']\n",
    "DataClass = getattr(medmnist, dataset_info['python_class'])\n",
    "\n",
    "# Transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# Load Full Datasets Globally\n",
    "full_train_dataset = DataClass(split='train', transform=data_transforms, download=True)\n",
    "val_dataset = DataClass(split='val', transform=data_transforms, download=True)\n",
    "test_dataset = DataClass(split='test', transform=data_transforms, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92_Qeb9yZOf8",
    "outputId": "3a390f42-5f6f-4817-c77e-13b3bea46956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 89996, Validation samples: 10004, Test samples: 7180\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train samples: {len(full_train_dataset)}, Validation samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wa8d54FhUZmJ"
   },
   "outputs": [],
   "source": [
    "NUM_PARTITIONS = 5\n",
    "BATCH_SIZE = 128\n",
    "LOCAL_EPOCHS = 5\n",
    "NUM_ROUNDS = 6\n",
    "\n",
    "\n",
    "def load_datasets(partition_id: int, num_partitions: int):\n",
    "    # Partition the training dataset into NUM_PARTITIONS\n",
    "    def partition_dataset(dataset, num_partitions):\n",
    "        dataset_size = len(dataset)\n",
    "        indices = np.random.permutation(dataset_size)  # Shuffle dataset indices\n",
    "        partition_size = dataset_size // num_partitions  # Size of each partition\n",
    "        partitions = [\n",
    "            Subset(dataset, indices[i * partition_size: (i + 1) * partition_size])\n",
    "            for i in range(num_partitions)\n",
    "        ]\n",
    "        return partitions\n",
    "\n",
    "    # Partition training and validation datasets\n",
    "    client_train_datasets = partition_dataset(full_train_dataset, num_partitions)\n",
    "    client_train_dataset = client_train_datasets[partition_id]\n",
    "\n",
    "    client_val_datasets = partition_dataset(val_dataset, num_partitions)\n",
    "    client_val_dataset = client_val_datasets[partition_id]\n",
    "\n",
    "    # Create DataLoaders\n",
    "    trainloader = DataLoader(client_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valloader = DataLoader(client_val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9WeI5-rWSBc",
    "outputId": "15ac8679-ae01-41b2-f732-e8fcdb3f0d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 4 Train Samples: 17999\n",
      "Client 4 Validation Samples: 2000\n",
      "Test Samples (Global): 7180\n"
     ]
    }
   ],
   "source": [
    "# Example: Load data for client 0\n",
    "partition_id = 4  # Specify client ID\n",
    "trainloader, valloader, testloader = load_datasets(partition_id=partition_id, num_partitions=NUM_PARTITIONS)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Client {partition_id} Train Samples: {len(trainloader.dataset)}\")\n",
    "print(f\"Client {partition_id} Validation Samples: {len(valloader.dataset)}\")\n",
    "print(f\"Test Samples (Global): {len(testloader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CPrpK82_5Brp"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # First convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)   # Pooling\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # Second convolution\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(120, 84)         # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(84, 10)         # Fully connected layer 3 (output)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 + ReLU + Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + ReLU + Pooling\n",
    "        x = x.view(x.size(0), -1)             # Flatten feature map\n",
    "        x = F.relu(self.fc1(x))               # Fully connected layer 1\n",
    "        x = F.relu(self.fc2(x))               # Fully connected layer 2\n",
    "        x = self.fc3(x)                       # Output layer\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net: nn.Module) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net: nn.Module, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net: nn.Module, trainloader: torch.utils.data.DataLoader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:  # Updated for PathMNIST DataLoader\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            labels = labels.squeeze().long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss:.4f}, accuracy {epoch_acc * 100:.2f}%\")\n",
    "\n",
    "\n",
    "def test(net: nn.Module, testloader: torch.utils.data.DataLoader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:  # Updated for PathMNIST DataLoader\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            labels = labels.squeeze().long()\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "id6QAAzx66rH"
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, partition_id, net, trainloader, valloader):\n",
    "        self.partition_id = partition_id\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        server_round = config[\"server_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "\n",
    "        print(f\"[Client {self.partition_id}, round {server_round}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=local_epochs)\n",
    "        return get_parameters(self.net), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader.dataset), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    # Initialize model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Fetch data partition information from context\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "\n",
    "    # Load datasets for this client\n",
    "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
    "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JnmUBTDwDgx9"
   },
   "outputs": [],
   "source": [
    "# The `evaluate` function will be called by Flower after every round\n",
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: NDArrays,\n",
    "    config: Dict[str, Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    # Initialize the model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load the test dataset (shared across all clients)\n",
    "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)  # Client ID 0 is irrelevant here\n",
    "\n",
    "    # Set the model's parameters to the latest global parameters\n",
    "    set_parameters(net, parameters)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = test(net, testloader)\n",
    "\n",
    "    # Log and return metrics\n",
    "    print(f\"[Server Round {server_round}] Evaluation - Loss: {loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return loss, {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MLIPdp_VFzU6"
   },
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": 1 if server_round < 2 else LOCAL_EPOCHS,\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HHzg56SB7IFG"
   },
   "outputs": [],
   "source": [
    "params = get_parameters(Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2M9SWo0F7mb0"
   },
   "outputs": [],
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    # Create FedAvg strategy with specified configurations\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit=0.3,                # Fraction of clients selected for training in each round\n",
    "        fraction_evaluate=0.3,          # Fraction of clients selected for evaluation\n",
    "        min_fit_clients=3,              # Minimum number of clients required for training\n",
    "        min_evaluate_clients=3,         # Minimum number of clients required for evaluation\n",
    "        min_available_clients=NUM_PARTITIONS,  # Total number of clients (NUM_PARTITIONS)\n",
    "        initial_parameters=ndarrays_to_parameters(params),  # Pass initial model parameters\n",
    "        evaluate_fn=evaluate,\n",
    "        on_fit_config_fn=fit_config\n",
    "    )\n",
    "\n",
    "    # Configure the server for multiple rounds of federated learning\n",
    "    config = ServerConfig(num_rounds=NUM_ROUNDS)  # Change `num_rounds` as needed\n",
    "\n",
    "    print(f\"Server initialized with {NUM_PARTITIONS} clients and {config.num_rounds} rounds.\")\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SN9QjzcZ8Lta"
   },
   "outputs": [],
   "source": [
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOFsxZdB7vRS",
    "outputId": "7a5a8ffc-d0a0-4155-a629-280192952d6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:flwr:Asyncio event loop already running.\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=6, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting federated simulation with 5 clients...\n",
      "Server initialized with 5 clients and 6 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.289621457718966, {'accuracy': 0.18635097493036212}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Round 0] Evaluation - Loss: 2.2896, Accuracy: 18.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=25396)\u001b[0m 2024-11-20 01:10:18.820010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=25396)\u001b[0m 2024-11-20 01:10:18.844531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=25396)\u001b[0m 2024-11-20 01:10:18.852654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=25396)\u001b[0m 2024-11-20 01:10:20.531495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 0, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 1.8442, accuracy 28.19%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 1, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 1.7836, accuracy 32.30%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 3, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 1.7555, accuracy 32.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 2.665029555036311, {'accuracy': 0.31142061281337047}, 50.81896580600005)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Round 1] Evaluation - Loss: 2.6650, Accuracy: 31.14%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 3] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 0, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 1.5288, accuracy 41.83%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 2: train loss 1.1937, accuracy 53.78%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 3: train loss 1.0785, accuracy 57.98%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 4: train loss 0.9978, accuracy 62.08%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 5: train loss 0.9385, accuracy 64.66%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 2, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 1.4814, accuracy 43.72%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 2: train loss 1.1688, accuracy 54.60%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 3: train loss 1.0863, accuracy 57.29%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 4: train loss 0.9930, accuracy 62.05%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 5: train loss 0.9494, accuracy 64.52%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 4, round 2] fit, config: {'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 1.4872, accuracy 43.97%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 2: train loss 1.1678, accuracy 54.75%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 3: train loss 1.0704, accuracy 58.22%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 4: train loss 1.0140, accuracy 61.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 5: train loss 0.9417, accuracy 64.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.9556933861029776, {'accuracy': 0.68008356545961}, 215.45561791199998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Round 2] Evaluation - Loss: 0.9557, Accuracy: 68.01%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 4] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 0, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 0.9210, accuracy 65.65%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 2: train loss 0.8491, accuracy 67.97%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 3: train loss 0.8304, accuracy 68.86%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 4: train loss 0.7997, accuracy 69.71%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 5: train loss 0.7883, accuracy 70.09%\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m [Client 2, round 3] fit, config: {'server_round': 3, 'local_epochs': 5}\n",
      "\u001b[36m(ClientAppActor pid=25396)\u001b[0m Epoch 1: train loss 0.9349, accuracy 64.91%\n"
     ]
    }
   ],
   "source": [
    "backend_config = {\"client_resources\": {\"num_cpus\": 2}}  # Default: 2 CPUs per client\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(\"CUDA is available. Allocating 1 GPU per client.\")\n",
    "    backend_config[\"client_resources\"][\"num_gpus\"] = 1\n",
    "\n",
    "# Start simulation\n",
    "print(f\"Starting federated simulation with {NUM_PARTITIONS} clients...\")\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,  # Number of clients participating\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
